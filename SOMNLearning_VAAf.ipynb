{"cells":[{"cell_type":"markdown","source":["**SomnLearning_VVA.ipynb**\n","<br>\n","<br>\n","Original file is located at\n","<br>\n","https://colab.research.google.com/drive/1xb_4igG3Uwx4kMRZj4o7X_OzLe3JHTcG\n","<br>\n","<br>\n","SOMN+RL\n","<br>\n","https://medium.com/turing-talks/pouse-um-m%C3%B3dulo-lunar-com-deep-q-learning-1f4395ea764\n","\n"],"metadata":{"id":"xRIJZ6u5Yy18"}},{"cell_type":"markdown","source":["# **1. Importar as bibliotecas**"],"metadata":{"id":"0xjLpAl5Yl0_"}},{"cell_type":"code","source":["import gym\n","import tensorflow as tf\n","import numpy as np\n"],"metadata":{"id":"oeLq9dBuYwbN","executionInfo":{"status":"ok","timestamp":1682477100583,"user_tz":180,"elapsed":4389,"user":{"displayName":"Frederic Menezes Ferreira","userId":"10241081141493327015"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# **2. Função para fazer a DQN**"],"metadata":{"id":"5aYsdIK7auA8"}},{"cell_type":"code","source":["def fazerDQN(alpha, n_acoes, input_dims, fc1, fc2):\n","    layers = tf.keras.layers\n","    DQN = tf.keras.models.Sequential()\n","    DQN.add(layers.Flatten(input_shape=(input_dims)))\n","    DQN.add(layers.Dense(fc1, activation='relu'))\n","    #### dropout  model.add(Dropout(0.2))\n","    DQN.add(layers.Dense(fc2, activation='relu'))\n","    DQN.add(layers.Dense(n_acoes, activation='relu'))\n","    \n","    DQN.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=alpha),loss='huber_loss')\n","    return DQN"],"metadata":{"id":"jICg6rJ9arM0","executionInfo":{"status":"ok","timestamp":1682477103860,"user_tz":180,"elapsed":1095,"user":{"displayName":"Frederic Menezes Ferreira","userId":"10241081141493327015"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# **3. Classe ExperienceReplay**"],"metadata":{"id":"_cl35l9Za9eN"}},{"cell_type":"code","source":["class ExperienceReplay():\n","    def __init__(self, mem_max, input_dims):\n","        self.mem_max = mem_max\n","        #tamanho máximo\n","        self.mem_counter = 0\n","        #contador de elementos\n","        self.s = np.zeros((self.mem_max, *input_dims), dtype=np.float32)\n","        self.s2 = np.zeros((self.mem_max, *input_dims),dtype=np.float32)\n","        self.r = np.zeros(self.mem_max, dtype = np.float32)\n","        self.a = np.zeros(self.mem_max, dtype = np.int32)\n","        self.terminal = np.zeros(self.mem_max, dtype=np.int32)\n","\n","    def salvar_experiencia(self, s, a, r, s2, teminado):\n","      index = self.mem_counter % self.mem_max\n","      self.s[index] = s # Estado 1\n","      self.s2[index] = s2 # Estado 2\n","      self.r[index] = r # Reward da Experiência\n","      self.a[index] = a # Ação da Experiência\n","      self.terminal[index] = 1 - int(teminado) # Estado terminal?\n","      self.mem_counter += 1\n","\n","    def amostra_aleatoria(self, tamanho_amostra):\n","        mem_max = min(self.mem_counter, self.mem_max)\n","        amostra = np.random.choice(mem_max, tamanho_amostra, replace=False)\n","        s = self.s[amostra]\n","        s2 = self.s2[amostra]\n","        r = self.r[amostra]\n","        a = self.a[amostra]\n","        terminal = self.terminal[amostra]\n","        return s, a, r, s2, terminal"],"metadata":{"id":"V5ybpLr6bKiN","executionInfo":{"status":"ok","timestamp":1682477106605,"user_tz":180,"elapsed":1,"user":{"displayName":"Frederic Menezes Ferreira","userId":"10241081141493327015"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# **4. Classe para Agente**"],"metadata":{"id":"jHz0ZMUcbh0e"}},{"cell_type":"code","source":["class Agente():\n","    def __init__(self, alpha, gamma, n_acoes, epsilon, tamanho_amostra,\n","                 input_dims, epsilon_dec=1e-3, epsilon_end=0.01,\n","                 mem_max=1000000, fname='dqn_saveVAft02.h5' ):\n","        self.acoes = [i for i in range(n_acoes)]\n","        self.gamma = gamma\n","        self.epsilon = epsilon\n","        self.epsilon_dec = epsilon_dec\n","        self.eps_min = epsilon_end\n","        self.tamanho_amostra = tamanho_amostra\n","        self.model_file = fname\n","        self.memoria = ExperienceReplay(mem_max, input_dims)\n","        self.q_eval = fazerDQN(alpha, n_acoes, input_dims, 256,256)\n","\n","    def salvar_experiencia(self, s, a, r, s2, terminado):\n","        self.memoria.salvar_experiencia(s, a, r, s2, terminado)\n","\n","    def escolher_acao(self, obs):\n","        if np.random.random() < self.epsilon:\n","          acao = np.random.choice(self.acoes)\n","        else:\n","          s = np.array([obs])      \n","          acoes = self.q_eval.predict(s)\n","          acao = np.argmax(acoes)\n","\n","        return acao\n","\n","    def aprender(self):\n","            if self.memoria.mem_counter < self.tamanho_amostra:\n","                return\n","            s, a, r, s2, terminados = self.memoria.amostra_aleatoria(self.tamanho_amostra)\n","            q_eval = self.q_eval.predict(s)\n","            q_next = self.q_eval.predict(s2)\n","            #print ('\\n A P R E N D E N D O .............', q_eval, q_next)\n","            q_target = np.copy(q_eval)\n","            batch_index = np.arange(self.tamanho_amostra, dtype=np.int32)\n","            q_target[batch_index, a] = r + self.gamma*np.max(q_next, axis=1)*terminados\n","            loss = self.q_eval.train_on_batch(s, q_target)\n","            if self.epsilon > self.eps_min:\n","                self.epsilon = self.epsilon - self.epsilon_dec\n","#            else:\n","#                self.eps_min\n","\n","            return loss\n","\n","    def save_model(self):\n","            self.q_eval.save(self.model_file)\n","    def load_model(self):\n","            self.q_eval = tf.keras.models.load_model(self.model_file)"],"metadata":{"id":"pwCPV0ZIbqBF","executionInfo":{"status":"ok","timestamp":1682477110380,"user_tz":180,"elapsed":1,"user":{"displayName":"Frederic Menezes Ferreira","userId":"10241081141493327015"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# **5. Ambiente**"],"metadata":{"id":"qkw0TsxwcFk8"}},{"cell_type":"markdown","source":["## **5.1 Importar Dependências**"],"metadata":{"id":"FJ3jJj0InGEk"}},{"cell_type":"code","source":["# ENVIRONMENT\n","import random\n","import numpy as np\n","from absl import flags\n","import gym\n","from gym import Env\n","from gym.spaces import Discrete, Tuple, Box\n","import torch"],"metadata":{"id":"BfLv2lhuna7N","executionInfo":{"status":"ok","timestamp":1682477119249,"user_tz":180,"elapsed":4080,"user":{"displayName":"Frederic Menezes Ferreira","userId":"10241081141493327015"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## **5.2 Classe Yard (*Pátio*)**"],"metadata":{"id":"RceyVIjRngn0"}},{"cell_type":"code","source":["class Yard:\n","  \n","  def __init__(self, Y, numFeat, typFeat):\n"," \n","    Yard.Y=Y\n","    Yard.yard = [0 for _ in range(numFeat)]\n","    Yard.cont=0\n","    Yard.space = Y"],"metadata":{"id":"ucojm7XsoCt1","executionInfo":{"status":"ok","timestamp":1682477121068,"user_tz":180,"elapsed":1,"user":{"displayName":"Frederic Menezes Ferreira","userId":"10241081141493327015"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## **5.2 Classe Demand (*Demanda*)**"],"metadata":{"id":"8yEnXN47r7JT"}},{"cell_type":"code","source":["class Demand:\n","  cont=1\n","#  Y=20,M=10,N=10,MAXDO=10,MAXAM=5,MAXPR=1.5,MAXPE=50,MAXFT=5,MAXMT=3,MAXTI=2,MAXEU = 30\n","  def __init__(self,M:int,N:int, MAXDO:int, MAXAM:int, MAXPR:float, MAXPE:int, MAXFT:int, MAXMT:int, MAXTI:int, MAXEU:int, t: int):\n","    Demand.M=M\n","    Demand.N=N\n","    Demand.MAXDO=MAXDO\n","    Demand.MAXAM=MAXAM\n","    Demand.MAXPR=MAXPR\n","    Demand.MAXPE=MAXPE\n","    Demand.MAXFT=MAXFT\n","    Demand.MAXMT=MAXMT\n","    Demand.MAXTI=MAXTI\n","    Demand.MAXEU=MAXEU\n","    Demand.EU = np.random.random(M)*MAXEU\n","    self.ST = -1                  ###free(-1) received0, ready1, rejected2, produced3, stored4 and delivered5   \n","\n"," #   self(t) \n","    Demand.cont +=1\n","  \n","  def __call__(self, t:int):\n","    \n","    self.CU = Demand.cont\n","#    self.PR = random.randrange(3,Demand.MAXPR)  below -----------------\n","    self.AM = 1 # random.randrange(1,Demand.MAXAM)\n","    self.PE = random.randint(1,Demand.MAXPE)\n","    self.ST = 0                  ###received0, ready1, rejected2, produced3, stored4 and delivered5\n","    self.FT = np.random.randint(0,Demand.MAXFT,self.M) \n","    if not np.any(self.FT):\n","        self.FT[1] = 1\n","\n","### Tempo    \n","    self.F = 0\n","    for i in range(self.M):\n","      self.F += int(self.FT[i]>0)\n","\n","    self.LT = int(self.F/2) + 2                      ###  --- 1.0*self.fun_tau() * self.F\n","    self.DI = t\n","    self.DO = t + self.LT + random.randint(0,Demand.MAXDO)\n","    \n","    self.CO = 0.0\n","    for j in range(Demand.M):\n","      self.CO += self.FT[j] * Demand.EU[j]\n","    self.CO = self.AM * self.CO\n","#    self.PR = Demand.MAXPR*self.CO\n","    self.PR = Demand.MAXPE\n","\n","    self.SP = 1.0*self.fun_gamma() ####* Yard.Y   #SPACE CONSUMPTION FACTOR\n","    self.VA = 1.0*self.fun_upsilon() \n","    self.SU = 1.0*self.fun_sigma() \n","    self.TP = self.DO - t\n","\n","  def fun_gamma(self) -> float:\n","    x = (self.AM*self.F)/(Demand.MAXAM * self.M)\n","    return x\n","\n","  def fun_tau(self) -> float:\n","    x = (self.AM*self.F)/(Demand.MAXAM * self.M)\n","    return x\n","\n","  def fun_upsilon(self) -> float:\n","    x = self.F/self.M\n","    return x\n","\n","  def fun_sigma(self) -> float:\n","    x = self.F/self.M\n","    return x\n","  \n","#  def fun_beta(self, IN, OU) -> float:\n"," #   x=0\n","#    for i in range(self.M):\n","#      if IN[i]==OU[i]:\n","#        x+=1\n","#    x = x/self.M\n","#    return x\n","     \n","#  def calculate_statics(self):"],"metadata":{"id":"9_v31H3bsCzM","executionInfo":{"status":"ok","timestamp":1682477123345,"user_tz":180,"elapsed":2,"user":{"displayName":"Frederic Menezes Ferreira","userId":"10241081141493327015"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## **5.3 Classe Somn (*Ambiente SOMN*)**"],"metadata":{"id":"X4A0Lg10sItz"}},{"cell_type":"code","source":["class Somn(Env):\n","\n","#  def __init__(self):\n","  def __init__(self, M:int,N:int,Y:int, MAXDO:int, \n","               MAXAM:int, MAXPR:int, MAXPE:int, MAXFT:int, \n","               MAXMT:int, MAXTI:int, MAXEU:int):\n","    Somn.time = 1\n","    self.M=M\n","    self.N=N\n","    self.Y=Y\n","    self.MAXDO=MAXDO\n","    self.MAXAM=MAXAM\n","    self.MAXPR=MAXPR\n","    self.MAXPE=MAXPE\n","    self.MAXFT=MAXFT\n","    self.MAXMT=MAXMT\n","    self.MAXTI=MAXTI\n","    self.MAXEU=MAXEU\n","    #self.MT = np.random.randint(0,MAXFT,M)\n","    self.EU = np.random.random(M)*MAXEU \n","    self.BA = np.random.randint(0,MAXFT,M)\n","    self.IN = np.random.randint(0,MAXFT,M)\n","    self.OU = np.random.randint(0,MAXFT,M)\n","\n","    self.state = np.zeros((N,5))\n","\n","    print('Inicializado', M, N , Y)\n","\n","    self.DE = [Demand(M,N,MAXDO,MAXAM,MAXPR,MAXPE,MAXFT,MAXMT,MAXTI,MAXEU,Somn.time) for _ in range(N)]\n","    self.YA = [Yard(Y,M,MAXFT) for _ in range(Y)]\n","\n","#### demais inicializações\n","    self.observation_space = Box(low=0, high=1, shape=(N, 5))\n","    self.action_space = Discrete(int(self.MAXDO/2)) # accept to produce or reject\n","\n","\n","  def readDemand(self):\n","    for i in range(Demand.N):\n","      if self.DE[i].ST == -1:    # or self.DE[i].ST == 0: ZERO não pode ser status de livre\n","        self.DE[i](Somn.time)\n"," \n","  def   match_demand_with_inventory(self,limiar: float, t:int)->bool:\n","    matched = False\n","    for i in range(Demand.N):\n","      for y in range(Yard.cont):\n","        match=0\n","  #      print('Y...', y, 'YA=', YA[y].yard,Yard.cont, 'l=', limiar)\n","        for j in range(Demand.M):\n","          #print('Y(y,j):', y,j, 'Y x D:', self.YA[y].yard[j],self.DE[i].FT[j], 'cont:', Yard.cont, 'l x m:', limiar, match)\n","          if self.DE[i].FT[j] > 0:\n","            if self.DE[i].FT[j] <= self.YA[y].yard[j]:\n","              match=match+1\n","          ### se for ZERO então não pode ter a caracteristica\n","          else:\n","            if self.YA[y].yard[j]==0:\n","              match=match+1\n","              \n","        if match >= limiar:\n","          print(\"\\n Match: Casou\", Yard.cont)\n","          self.YA[y].yard = self.YA[Yard.cont-1].yard  ## apaga o registro de match com o último da lista\n","          Yard.cont -=1\n","          self.DE[i].ST = 3  ## produced status\n","          matched = True\n","\n","      #print(\"\\n Match: Saiu\", Yard.cont)\n","      return matched\n","\n","  def product_scheduling (self,t:int, action):\n","    for i in range(self.N):\n","      if self.DE[i].ST == 1:\n","        if self.DE[i].DO  > (t + self.DE[i].LT + action):\n","          self.DE[i].ST = 3  ## produced status --- remember to run time for each case\n","          self.OU -= self.DE[i].FT ## CONSOME OS RECURSOS\n","          self.DE[i].TP = t + self.DE[i].LT  + 3 #   --- trocar por distribuição poison --- ou por algo que dependa de AM random.randint(1,Demand.MAXTI) \n","          print('\\n **** PRODUCED because', self.DE[i].DO, '>', t + self.DE[i].LT + action)\n","        else:\n","          self.DE[i].ST = 2  ## rejected status\n","          self.OU -= self.DE[i].FT  ### libera do buffer de produção\n","          self.BA += self.DE[i].FT ## devolve para o saldo para os próximos\n","          print('\\n **** REJECTED by DO', self.DE[i].DO, ' <= DI+LT+act', t , self.DE[i].LT , action)\n","  \n","\n","  def product_destination(self,  t: int):\n","    for i in range(Demand.N):\n","        if self.DE[i].ST == 3:\n","          if self.DE[i].TP < t:   ### TP eh resultado de LT(#f) + RAND\n","            if t < self.DE[i].DO:\n","              self.DE[i].ST = 5  ## produced status --- remember to run time for each case\n","              print(\"\\n Destination: Enviou\", Yard.cont)\n","            else:\n","              self.DE[i].ST = 4  ## produced status\n","              if Yard.cont < Yard.Y-1:\n","                self.YA[Yard.cont].yard = self.DE[i].FT\n","                Yard.cont += 1\n","                print(\"\\n Destination: Armazenou no YARD\", Yard.cont)\n","              else:\n","                self.DE[i].ST = -2  ## NAO CABE ... REJEITADO COM GERAÇÃO DE LIXO (CASO MAIS GRAVE)\n","  \n","  def stock_covers_demand(self, t):\n","    covered = True\n","    \n","    for i in range(self.N):\n","      if self.DE[i].ST == 0:\n","\n","        DF = self.BA - self.DE[i].FT\n","\n","        OR = np.array([abs(i) if i < 0 else 0 for i in DF])   # O QUE PRECISA SER COMPRADO\n","        #print('\\n ORDER from ', DF, ':', OR)\n","        if not np.any(OR):\n","          self.DE[i].ST=1 \n","          self.BA -=  np.array(DF)    ### ATUALIZA O SALDO\n","          self.OU += np.array(DF)   ### ATUALIZA A SAÍDA\n","          #print('\\n balance:', self.BA,  'because not buying',self.OU)\n","        else:\n","          covered = False\n","          self.IN += np.array(OR)  ## ATUALIZA O TOTAL DE COMPRAVEIS \n","          #print('\\n balance: ', self.BA, 'because buying',OR, 'accumulating', self.IN)\n","    return covered\n","\n"," # def order_raw_material(self, t: int):\n"," #   self.IN = [random.randint(0,i) if i > 0 else 0 for i in self.IN]\n"," #   return self.IN\n","\n","  def eval_final_states(self)->float:\n","    totProfit = 0.0\n","    totReward = 0.0\n","    totPenalty = 0.0\n","    for i in range(self.N):\n","      if self.DE[i].ST == 2:\n","        self.DE[i].ST = -1      # LIBERA O ESPAÇO APÓS CONTABILIZADO\n","        totProfit += (self.DE[i].AM * self.DE[i].PR)\n","        print('REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv')\n","      if self.DE[i].ST == -2:\n","        totPenalty += self.DE[i].CO\n","        self.DE[i].ST = -1      # LIBERA O ESPAÇO APÓS CONTABILIZADO\n","        print('PREJUIZO $$$$$$$$$$$$$$$$$$$$$$$$$')\n","      if self.DE[i].ST == 4:\n","        totPenalty += totReward / (Yard.space - Yard.cont+1) ### penalidade inversamente proporcional ao espaço remanescente\n","        self.DE[i].ST = -1      # LIBERA O ESPAÇO APÓS CONTABILIZADO\n","        totProfit += (self.DE[i].AM * self.DE[i].PR)\n","        print('STORED <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')\n","      if self.DE[i].ST == 5:\n","        totReward += (self.DE[i].AM * self.DE[i].PR)\n","        self.DE[i].ST = -1      # LIBERA O ESPAÇO APÓS CONTABILIZADO\n","        totProfit += (self.DE[i].AM * self.DE[i].PR)\n","        print('REWARD ******************************')\n","    totReward -= totPenalty\n","    print ('REW+PEN+PRO', totReward, totPenalty, totProfit)\n","    return totReward, totPenalty, totProfit\n","\n","  def reset(self):\n","    self.MT = np.random.randint(0,self.MAXFT,self.M)\n","    self.EU = np.random.random(self.M)*self.MAXEU \n","    self.BA = np.random.randint(0,self.MAXFT,self.M)\n","    self.IN = np.random.randint(0,self.MAXFT,self.M)\n","    self.OU = np.random.randint(0,self.MAXFT,self.M)\n","    Somn.time = 0\n","\n","    self.YA = [Yard(self.Y,self.M,self.MAXFT) for _ in range(self.Y)]\n","\n","    arrayState = []\n","    for i in range(self.N):\n","      self.DE[i](Somn.time)\n","      aux_row = [self.DE[i].ST,\n","                 Somn.time,\n","                 self.DE[i].LT,\n","#                 self.DE[i].VA,\n","#                 self.DE[i].SU,\n","#                 self.DE[i].PR,\n","                self.DE[i].DO,\n","                 self.DE[i].TP]\n","      arrayState.append(aux_row)\n","\n","    #self.state = torch.from_numpy(np.array(arrayState))\n","    self.state = np.array(arrayState)\n","    return self.state\n","\n","\n","\n","\n","  def step(self, action):\n","    # Atualiza tudo aqui e devolve o próximo estado: n_state, reward, done, info\n","    # n_state: próximo estado; reward: recompensa da ação; done: flag de conclusão; info: informaões extras (opcional)\n","    # primeira versão vai fazer uma iteração para cada episódio ... O Tempo t precisa ser controlado\n","\n","### receive RAW MATERIAL AND ORDERS (DEMANDS)    \n","    self.MT = np.array([random.randint(0,i) if i > 0 else 0 for i in self.IN])\n","    self.readDemand()\n","\n","### IF PREVIOUS ORDERS INVENTORY AVAILABLE, PLEASE DISPATCH\n","    if self.match_demand_with_inventory(self.MAXFT/5, Somn.time):  \n","      self.product_destination(Somn.time)\n","\n","### ANYWAY, UPDATE BALANCE AND INCOME RAW MATERIAL REGARDING MT RECEIVED    \n","    self.IN -= self.MT\n","    self.BA += self.MT\n","\n","### IF RAW MATERIAL INVENTORY DOES NOT COVER PLEASE REQUEST RAW MATERIAL\n","    if not self.stock_covers_demand(Somn.time):          \n","      self.IN = [random.randint(0,i) if i > 0 else 0 for i in self.IN] \n","\n","### ANYWAY START PRODUCING AND DISPATCHING\n","    self.product_scheduling (Somn.time, action)\n","    self.product_destination(Somn.time)\n","    Somn.time += 1\n","\n","### ORDINARY PROCEDURES IN STEP METHOD INCLUDING REWARD BY INSPECTING FINAL STATES\n","### 1 STATE\n","    arrayState = []\n","\n","    for i in range(self.N):\n","      aux_row = [self.DE[i].ST,\n","                 Somn.time,\n","#                 self.DE[i].SP,\n","                 self.DE[i].LT,\n","#                 self.DE[i].VA,\n","#                 self.DE[i].SU,\n","#                 self.DE[i].PR,\n","                self.DE[i].DO,\n","                self.DE[i].TP]\n","      arrayState.append(aux_row)\n","\n","    self.state = np.array(arrayState)\n","\n","### 2 REWARD                                 \n","    reward, penalty, exprofit = self.eval_final_states() # aqui vai a função que calcula a recompensa\n","\n","### 3 FINAL CONDITION\n","    done = False\n","    # if penalty>0:\n","    #   reward =0\n","    #   #print('\\n D -- O -- N -- E --', self.state)\n","    #   done = True\n","    \n","    if Somn.time >= 2*self.N:\n","      #print('\\n D -- O -- N -- E --', self.state)\n","      done = True\n","    \n","    info = {} # Informações adicionais\n","    return self.state, reward, done, info, exprofit\n","\n","\n","  def render(self):\n","    print(\"Current state (RENDER): \", self.state)"],"metadata":{"id":"zQRV0hb6sVW9","executionInfo":{"status":"ok","timestamp":1682477126074,"user_tz":180,"elapsed":1,"user":{"displayName":"Frederic Menezes Ferreira","userId":"10241081141493327015"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# **6. Teste do Ambiente**"],"metadata":{"id":"L_02kCIi26p5"}},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"],"metadata":{"id":"Fu4HMBgI3FR5","executionInfo":{"status":"ok","timestamp":1682477137187,"user_tz":180,"elapsed":538,"user":{"displayName":"Frederic Menezes Ferreira","userId":"10241081141493327015"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["env = Somn(Y=10,M=5,N=7,MAXDO=5,MAXAM=5,MAXPR=1.5,MAXPE=10,MAXFT=5,MAXMT=3,MAXTI=2,MAXEU = 10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iv0i68ds25-K","executionInfo":{"status":"ok","timestamp":1682477138820,"user_tz":180,"elapsed":1,"user":{"displayName":"Frederic Menezes Ferreira","userId":"10241081141493327015"}},"outputId":"0457639b-2b9a-4bc6-ad2f-aae9e6d93f61"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Inicializado 5 7 10\n"]}]},{"cell_type":"code","source":["env.reset()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WWzRSSTZCh1P","executionInfo":{"status":"ok","timestamp":1682477144785,"user_tz":180,"elapsed":1,"user":{"displayName":"Frederic Menezes Ferreira","userId":"10241081141493327015"}},"outputId":"421e3e41-6d8a-4a60-dcba-cf4b558e250d"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 0, 4, 8, 8],\n","       [0, 0, 3, 8, 8],\n","       [0, 0, 4, 5, 5],\n","       [0, 0, 4, 7, 7],\n","       [0, 0, 4, 4, 4],\n","       [0, 0, 4, 7, 7],\n","       [0, 0, 4, 8, 8]])"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["env.action_space"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rhp4xFEE3SVq","executionInfo":{"status":"ok","timestamp":1682477150697,"user_tz":180,"elapsed":609,"user":{"displayName":"Frederic Menezes Ferreira","userId":"10241081141493327015"}},"outputId":"4ead2d3b-8bcf-4396-95fd-3e8b83fbf0d6"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Discrete(2)"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["env.observation_space"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GX49zsJJ5WxB","executionInfo":{"status":"ok","timestamp":1682477152410,"user_tz":180,"elapsed":2,"user":{"displayName":"Frederic Menezes Ferreira","userId":"10241081141493327015"}},"outputId":"5a9c7681-e3aa-4323-b5cf-33a9f91aa858"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Box(0.0, 1.0, (7, 5), float32)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["env.observation_space.sample()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7PMwQRT5CuGc","executionInfo":{"status":"ok","timestamp":1682477157092,"user_tz":180,"elapsed":1456,"user":{"displayName":"Frederic Menezes Ferreira","userId":"10241081141493327015"}},"outputId":"cff74bf9-99ba-4797-c401-1cfcd3deb534"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.7046489 , 0.7440869 , 0.9011658 , 0.81376594, 0.56247777],\n","       [0.09421022, 0.3031969 , 0.10398153, 0.08508241, 0.522066  ],\n","       [0.678194  , 0.4534873 , 0.3844842 , 0.68179405, 0.29962772],\n","       [0.70126045, 0.47080094, 0.9147458 , 0.42501524, 0.31724912],\n","       [0.37589842, 0.6925429 , 0.60620356, 0.7641043 , 0.27958304],\n","       [0.57552177, 0.95550084, 0.38354605, 0.30717075, 0.9485589 ],\n","       [0.6927634 , 0.37557918, 0.14505123, 0.69453645, 0.18324496]],\n","      dtype=float32)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["env.state"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0UP730a-6n46","executionInfo":{"status":"ok","timestamp":1682477169246,"user_tz":180,"elapsed":548,"user":{"displayName":"Frederic Menezes Ferreira","userId":"10241081141493327015"}},"outputId":"65e10799-dd2b-45b9-d5e3-10e4a27dc417"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 0, 4, 8, 8],\n","       [0, 0, 3, 8, 8],\n","       [0, 0, 4, 5, 5],\n","       [0, 0, 4, 7, 7],\n","       [0, 0, 4, 4, 4],\n","       [0, 0, 4, 7, 7],\n","       [0, 0, 4, 8, 8]])"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["episodes = 5\n","for episode in range(1, episodes+1):\n","    state = env.reset()\n","    done = False\n","    score = 0 \n","    \n","    while not done:\n","        env.render()\n","        action = env.action_space.sample()\n","        n_state, reward, done, info, exprofit = env.step(action)\n","        \n","        score+=reward\n","    print('################################################# Episode:{} Score:{}'.format(episode, score))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"--DU5oWh7L08","executionInfo":{"status":"ok","timestamp":1682477175401,"user_tz":180,"elapsed":398,"user":{"displayName":"Frederic Menezes Ferreira","userId":"10241081141493327015"}},"outputId":"fb5562cd-597d-4b2c-daef-3d49017247b2"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Current state (RENDER):  [[0 0 3 5 5]\n"," [0 0 4 7 7]\n"," [0 0 4 5 5]\n"," [0 0 4 5 5]\n"," [0 0 4 7 7]\n"," [0 0 4 5 5]\n"," [0 0 3 8 8]]\n","\n"," **** PRODUCED because 5 > 4\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[3 1 3 5 6]\n"," [0 1 4 7 7]\n"," [0 1 4 5 5]\n"," [0 1 4 5 5]\n"," [0 1 4 7 7]\n"," [0 1 4 5 5]\n"," [0 1 3 8 8]]\n","\n"," **** REJECTED by DO 5  <= DI+LT+act 1 4 1\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 0.0 0.0 10.0\n","Current state (RENDER):  [[3 2 3 5 6]\n"," [0 2 4 7 7]\n"," [2 2 4 5 5]\n"," [0 2 4 5 5]\n"," [0 2 4 7 7]\n"," [0 2 4 5 5]\n"," [0 2 3 8 8]]\n","\n"," **** REJECTED by DO 7  <= DI+LT+act 2 4 1\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 0.0 0.0 10.0\n","Current state (RENDER):  [[3 3 3 5 6]\n"," [0 3 4 7 7]\n"," [2 3 4 7 5]\n"," [0 3 4 5 5]\n"," [0 3 4 7 7]\n"," [0 3 4 5 5]\n"," [0 3 3 8 8]]\n","\n"," **** REJECTED by DO 7  <= DI+LT+act 3 4 1\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 0.0 0.0 10.0\n","Current state (RENDER):  [[3 4 3 5 6]\n"," [2 4 4 7 7]\n"," [0 4 3 7 4]\n"," [0 4 4 5 5]\n"," [0 4 4 7 7]\n"," [0 4 4 5 5]\n"," [0 4 3 8 8]]\n","\n"," **** REJECTED by DO 7  <= DI+LT+act 4 3 1\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 0.0 0.0 10.0\n","Current state (RENDER):  [[ 3  5  3  5  6]\n"," [ 0  5  4 11  7]\n"," [ 2  5  3  7  4]\n"," [ 0  5  4  5  5]\n"," [ 0  5  4  7  7]\n"," [ 0  5  4  5  5]\n"," [ 0  5  3  8  8]]\n","\n"," **** PRODUCED because 11 > 9\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[ 3  6  3  5  6]\n"," [ 3  6  4 11 12]\n"," [ 0  6  4 11  6]\n"," [ 0  6  4  5  5]\n"," [ 0  6  4  7  7]\n"," [ 0  6  4  5  5]\n"," [ 0  6  3  8  8]]\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[ 3  7  3  5  6]\n"," [ 3  7  4 11 12]\n"," [ 0  7  4 11  6]\n"," [ 0  7  4  5  5]\n"," [ 0  7  4  7  7]\n"," [ 0  7  4  5  5]\n"," [ 0  7  3  8  8]]\n","\n"," **** REJECTED by DO 11  <= DI+LT+act 7 4 1\n","\n"," Destination: Armazenou no YARD 1\n","STORED <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 0.0 0.0 20.0\n","Current state (RENDER):  [[ 4  8  3  5  6]\n"," [ 3  8  4 11 12]\n"," [ 2  8  4 11  6]\n"," [ 0  8  4  5  5]\n"," [ 0  8  4  7  7]\n"," [ 0  8  4  5  5]\n"," [ 0  8  3  8  8]]\n","\n"," Match: Casou 1\n","\n"," Destination: Enviou 0\n","\n"," **** REJECTED by DO 12  <= DI+LT+act 8 4 0\n","REWARD ******************************\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 10.0 0.0 20.0\n","Current state (RENDER):  [[ 5  9  4 15  7]\n"," [ 3  9  4 11 12]\n"," [ 2  9  4 12  4]\n"," [ 0  9  4  5  5]\n"," [ 0  9  4  7  7]\n"," [ 0  9  4  5  5]\n"," [ 0  9  3  8  8]]\n","\n"," **** PRODUCED because 16 > 12\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[ 3 10  3 16 15]\n"," [ 3 10  4 11 12]\n"," [ 0 10  4 18  9]\n"," [ 0 10  4  5  5]\n"," [ 0 10  4  7  7]\n"," [ 0 10  4  5  5]\n"," [ 0 10  3  8  8]]\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[ 3 11  3 16 15]\n"," [ 3 11  4 11 12]\n"," [ 0 11  4 18  9]\n"," [ 0 11  4  5  5]\n"," [ 0 11  4  7  7]\n"," [ 0 11  4  5  5]\n"," [ 0 11  3  8  8]]\n","\n"," **** REJECTED by DO 5  <= DI+LT+act 11 4 1\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 0.0 0.0 10.0\n","Current state (RENDER):  [[ 3 12  3 16 15]\n"," [ 3 12  4 11 12]\n"," [ 0 12  4 18  9]\n"," [ 2 12  4  5  5]\n"," [ 0 12  4  7  7]\n"," [ 0 12  4  5  5]\n"," [ 0 12  3  8  8]]\n","\n"," **** REJECTED by DO 7  <= DI+LT+act 12 4 1\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 0.0 0.0 10.0\n","Current state (RENDER):  [[ 3 13  3 16 15]\n"," [ 3 13  4 11 12]\n"," [ 0 13  4 18  9]\n"," [ 0 13  4 20  8]\n"," [ 2 13  4  7  7]\n"," [ 0 13  4  5  5]\n"," [ 0 13  3  8  8]]\n","\n"," **** PRODUCED because 18 > 17\n","\n"," Destination: Armazenou no YARD 1\n","STORED <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","REW+PEN+PRO 0.0 0.0 10.0\n","################################################# Episode:1 Score:10.0\n","Current state (RENDER):  [[0 0 4 7 7]\n"," [0 0 4 5 5]\n"," [0 0 4 8 8]\n"," [0 0 4 8 8]\n"," [0 0 3 5 5]\n"," [0 0 3 3 3]\n"," [0 0 4 6 6]]\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[0 1 4 7 7]\n"," [0 1 4 5 5]\n"," [0 1 4 8 8]\n"," [0 1 4 8 8]\n"," [0 1 3 5 5]\n"," [0 1 3 3 3]\n"," [0 1 4 6 6]]\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[0 2 4 7 7]\n"," [0 2 4 5 5]\n"," [0 2 4 8 8]\n"," [0 2 4 8 8]\n"," [0 2 3 5 5]\n"," [0 2 3 3 3]\n"," [0 2 4 6 6]]\n","\n"," **** REJECTED by DO 5  <= DI+LT+act 2 3 0\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 0.0 0.0 10.0\n","Current state (RENDER):  [[0 3 4 7 7]\n"," [0 3 4 5 5]\n"," [0 3 4 8 8]\n"," [0 3 4 8 8]\n"," [2 3 3 5 5]\n"," [0 3 3 3 3]\n"," [0 3 4 6 6]]\n","\n"," **** REJECTED by DO 6  <= DI+LT+act 3 4 1\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 0.0 0.0 10.0\n","Current state (RENDER):  [[ 0  4  4  7  7]\n"," [ 0  4  4  5  5]\n"," [ 0  4  4  8  8]\n"," [ 0  4  4  8  8]\n"," [ 0  4  4 11  8]\n"," [ 0  4  3  3  3]\n"," [ 2  4  4  6  6]]\n","\n"," **** REJECTED by DO 7  <= DI+LT+act 4 4 0\n","\n"," **** REJECTED by DO 3  <= DI+LT+act 4 3 0\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 0.0 0.0 20.0\n","Current state (RENDER):  [[ 2  5  4  7  7]\n"," [ 0  5  4  5  5]\n"," [ 0  5  4  8  8]\n"," [ 0  5  4  8  8]\n"," [ 0  5  4 11  8]\n"," [ 2  5  3  3  3]\n"," [ 0  5  4 12  8]]\n","\n"," **** REJECTED by DO 9  <= DI+LT+act 5 4 1\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 0.0 0.0 10.0\n","Current state (RENDER):  [[ 2  6  4  9  4]\n"," [ 0  6  4  5  5]\n"," [ 0  6  4  8  8]\n"," [ 0  6  4  8  8]\n"," [ 0  6  4 11  8]\n"," [ 0  6  4 11  6]\n"," [ 0  6  4 12  8]]\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[ 0  7  4 15  9]\n"," [ 0  7  4  5  5]\n"," [ 0  7  4  8  8]\n"," [ 0  7  4  8  8]\n"," [ 0  7  4 11  8]\n"," [ 0  7  4 11  6]\n"," [ 0  7  4 12  8]]\n","\n"," **** PRODUCED because 15 > 12\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[ 3  8  4 15 14]\n"," [ 0  8  4  5  5]\n"," [ 0  8  4  8  8]\n"," [ 0  8  4  8  8]\n"," [ 0  8  4 11  8]\n"," [ 0  8  4 11  6]\n"," [ 0  8  4 12  8]]\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[ 3  9  4 15 14]\n"," [ 0  9  4  5  5]\n"," [ 0  9  4  8  8]\n"," [ 0  9  4  8  8]\n"," [ 0  9  4 11  8]\n"," [ 0  9  4 11  6]\n"," [ 0  9  4 12  8]]\n","\n"," **** REJECTED by DO 5  <= DI+LT+act 9 4 0\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 0.0 0.0 10.0\n","Current state (RENDER):  [[ 3 10  4 15 14]\n"," [ 2 10  4  5  5]\n"," [ 0 10  4  8  8]\n"," [ 0 10  4  8  8]\n"," [ 0 10  4 11  8]\n"," [ 0 10  4 11  6]\n"," [ 0 10  4 12  8]]\n","\n"," **** PRODUCED because 14 > 13\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[ 3 11  4 15 14]\n"," [ 3 11  3 14 16]\n"," [ 0 11  4  8  8]\n"," [ 0 11  4  8  8]\n"," [ 0 11  4 11  8]\n"," [ 0 11  4 11  6]\n"," [ 0 11  4 12  8]]\n","\n"," **** REJECTED by DO 12  <= DI+LT+act 11 4 0\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 0.0 0.0 10.0\n","Current state (RENDER):  [[ 3 12  4 15 14]\n"," [ 3 12  3 14 16]\n"," [ 0 12  4  8  8]\n"," [ 0 12  4  8  8]\n"," [ 0 12  4 11  8]\n"," [ 0 12  4 11  6]\n"," [ 2 12  4 12  8]]\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[ 3 13  4 15 14]\n"," [ 3 13  3 14 16]\n"," [ 0 13  4  8  8]\n"," [ 0 13  4  8  8]\n"," [ 0 13  4 11  8]\n"," [ 0 13  4 11  6]\n"," [ 0 13  3 19  7]]\n","\n"," **** PRODUCED because 19 > 16\n","REW+PEN+PRO 0.0 0.0 0.0\n","################################################# Episode:2 Score:0.0\n","Current state (RENDER):  [[0 0 4 9 9]\n"," [0 0 4 9 9]\n"," [0 0 4 7 7]\n"," [0 0 4 6 6]\n"," [0 0 4 7 7]\n"," [0 0 4 9 9]\n"," [0 0 4 6 6]]\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[0 1 4 9 9]\n"," [0 1 4 9 9]\n"," [0 1 4 7 7]\n"," [0 1 4 6 6]\n"," [0 1 4 7 7]\n"," [0 1 4 9 9]\n"," [0 1 4 6 6]]\n","\n"," **** PRODUCED because 9 > 6\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[3 2 4 9 8]\n"," [0 2 4 9 9]\n"," [0 2 4 7 7]\n"," [0 2 4 6 6]\n"," [0 2 4 7 7]\n"," [0 2 4 9 9]\n"," [0 2 4 6 6]]\n","\n"," **** PRODUCED because 9 > 7\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[3 3 4 9 8]\n"," [3 3 4 9 9]\n"," [0 3 4 7 7]\n"," [0 3 4 6 6]\n"," [0 3 4 7 7]\n"," [0 3 4 9 9]\n"," [0 3 4 6 6]]\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[3 4 4 9 8]\n"," [3 4 4 9 9]\n"," [0 4 4 7 7]\n"," [0 4 4 6 6]\n"," [0 4 4 7 7]\n"," [0 4 4 9 9]\n"," [0 4 4 6 6]]\n","\n"," **** REJECTED by DO 7  <= DI+LT+act 4 4 0\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 0.0 0.0 10.0\n","Current state (RENDER):  [[3 5 4 9 8]\n"," [3 5 4 9 9]\n"," [0 5 4 7 7]\n"," [0 5 4 6 6]\n"," [2 5 4 7 7]\n"," [0 5 4 9 9]\n"," [0 5 4 6 6]]\n","\n"," **** REJECTED by DO 9  <= DI+LT+act 5 4 0\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 0.0 0.0 10.0\n","Current state (RENDER):  [[3 6 4 9 8]\n"," [3 6 4 9 9]\n"," [0 6 4 7 7]\n"," [0 6 4 6 6]\n"," [2 6 4 9 4]\n"," [0 6 4 9 9]\n"," [0 6 4 6 6]]\n","\n"," **** REJECTED by DO 6  <= DI+LT+act 6 4 1\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 0.0 0.0 10.0\n","Current state (RENDER):  [[ 3  7  4  9  8]\n"," [ 3  7  4  9  9]\n"," [ 0  7  4  7  7]\n"," [ 0  7  4  6  6]\n"," [ 0  7  4 15  9]\n"," [ 0  7  4  9  9]\n"," [ 2  7  4  6  6]]\n","\n"," **** REJECTED by DO 7  <= DI+LT+act 7 4 0\n","\n"," **** PRODUCED because 14 > 10\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 0.0 0.0 10.0\n","Current state (RENDER):  [[ 3  8  4  9  8]\n"," [ 3  8  4  9  9]\n"," [ 2  8  4  7  7]\n"," [ 0  8  4  6  6]\n"," [ 0  8  4 15  9]\n"," [ 0  8  4  9  9]\n"," [ 3  8  3 14 13]]\n","\n"," **** REJECTED by DO 6  <= DI+LT+act 8 4 0\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 0.0 0.0 10.0\n","Current state (RENDER):  [[ 3  9  4  9  8]\n"," [ 3  9  4  9  9]\n"," [ 0  9  4 17  9]\n"," [ 2  9  4  6  6]\n"," [ 0  9  4 15  9]\n"," [ 0  9  4  9  9]\n"," [ 3  9  3 14 13]]\n","\n"," **** PRODUCED because 15 > 14\n","\n"," Destination: Armazenou no YARD 1\n","STORED <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","REW+PEN+PRO 0.0 0.0 10.0\n","Current state (RENDER):  [[ 4 10  4  9  8]\n"," [ 3 10  4  9  9]\n"," [ 0 10  4 17  9]\n"," [ 0 10  4 15  6]\n"," [ 3 10  4 15 16]\n"," [ 0 10  4  9  9]\n"," [ 3 10  3 14 13]]\n","\n"," Match: Casou 1\n","\n"," Destination: Enviou 0\n","\n"," Destination: Armazenou no YARD 1\n","REWARD ******************************\n","STORED <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","REW+PEN+PRO 9.0 1.0 20.0\n","Current state (RENDER):  [[ 5 11  4 15  5]\n"," [ 4 11  4  9  9]\n"," [ 0 11  4 17  9]\n"," [ 0 11  4 15  6]\n"," [ 3 11  4 15 16]\n"," [ 0 11  4  9  9]\n"," [ 3 11  3 14 13]]\n","\n"," Match: Casou 1\n","\n"," Destination: Enviou 0\n","REWARD ******************************\n","REW+PEN+PRO 10.0 0.0 10.0\n","Current state (RENDER):  [[ 5 12  3 16  5]\n"," [ 0 12  4 18  7]\n"," [ 0 12  4 17  9]\n"," [ 0 12  4 15  6]\n"," [ 3 12  4 15 16]\n"," [ 0 12  4  9  9]\n"," [ 3 12  3 14 13]]\n","\n"," **** PRODUCED because 20 > 16\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[ 3 13  4 20 19]\n"," [ 0 13  4 18  7]\n"," [ 0 13  4 17  9]\n"," [ 0 13  4 15  6]\n"," [ 3 13  4 15 16]\n"," [ 0 13  4  9  9]\n"," [ 3 13  3 14 13]]\n","REW+PEN+PRO 0.0 0.0 0.0\n","################################################# Episode:3 Score:19.0\n","Current state (RENDER):  [[0 0 4 7 7]\n"," [0 0 4 5 5]\n"," [0 0 4 4 4]\n"," [0 0 4 7 7]\n"," [0 0 3 3 3]\n"," [0 0 4 9 9]\n"," [0 0 3 7 7]]\n","\n"," **** PRODUCED because 7 > 5\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[3 1 4 7 7]\n"," [0 1 4 5 5]\n"," [0 1 4 4 4]\n"," [0 1 4 7 7]\n"," [0 1 3 3 3]\n"," [0 1 4 9 9]\n"," [0 1 3 7 7]]\n","\n"," **** PRODUCED because 7 > 5\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[3 2 4 7 7]\n"," [0 2 4 5 5]\n"," [0 2 4 4 4]\n"," [0 2 4 7 7]\n"," [0 2 3 3 3]\n"," [0 2 4 9 9]\n"," [3 2 3 7 7]]\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[3 3 4 7 7]\n"," [0 3 4 5 5]\n"," [0 3 4 4 4]\n"," [0 3 4 7 7]\n"," [0 3 3 3 3]\n"," [0 3 4 9 9]\n"," [3 3 3 7 7]]\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[3 4 4 7 7]\n"," [0 4 4 5 5]\n"," [0 4 4 4 4]\n"," [0 4 4 7 7]\n"," [0 4 3 3 3]\n"," [0 4 4 9 9]\n"," [3 4 3 7 7]]\n","\n"," **** REJECTED by DO 5  <= DI+LT+act 4 4 1\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 0.0 0.0 10.0\n","Current state (RENDER):  [[3 5 4 7 7]\n"," [2 5 4 5 5]\n"," [0 5 4 4 4]\n"," [0 5 4 7 7]\n"," [0 5 3 3 3]\n"," [0 5 4 9 9]\n"," [3 5 3 7 7]]\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[ 3  6  4  7  7]\n"," [ 0  6  4 13  8]\n"," [ 0  6  4  4  4]\n"," [ 0  6  4  7  7]\n"," [ 0  6  3  3  3]\n"," [ 0  6  4  9  9]\n"," [ 3  6  3  7  7]]\n","\n"," **** REJECTED by DO 4  <= DI+LT+act 6 4 1\n","\n"," **** REJECTED by DO 3  <= DI+LT+act 6 3 1\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 0.0 0.0 20.0\n","Current state (RENDER):  [[ 3  7  4  7  7]\n"," [ 0  7  4 13  8]\n"," [ 2  7  4  4  4]\n"," [ 0  7  4  7  7]\n"," [ 2  7  3  3  3]\n"," [ 0  7  4  9  9]\n"," [ 3  7  3  7  7]]\n","\n"," **** PRODUCED because 14 > 11\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[ 3  8  4  7  7]\n"," [ 0  8  4 13  8]\n"," [ 3  8  3 14 13]\n"," [ 0  8  4  7  7]\n"," [ 0  8  4 15  8]\n"," [ 0  8  4  9  9]\n"," [ 3  8  3  7  7]]\n","\n"," Destination: Armazenou no YARD 1\n","\n"," Destination: Armazenou no YARD 2\n","STORED <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","STORED <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","REW+PEN+PRO 0.0 0.0 20.0\n","Current state (RENDER):  [[ 4  9  4  7  7]\n"," [ 0  9  4 13  8]\n"," [ 3  9  3 14 13]\n"," [ 0  9  4  7  7]\n"," [ 0  9  4 15  8]\n"," [ 0  9  4  9  9]\n"," [ 4  9  3  7  7]]\n","\n"," Match: Casou 2\n","\n"," Match: Casou 1\n","\n"," **** PRODUCED because 15 > 13\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[ 3 10  4 18  9]\n"," [ 0 10  4 13  8]\n"," [ 3 10  3 14 13]\n"," [ 0 10  4  7  7]\n"," [ 3 10  4 15 16]\n"," [ 0 10  4  9  9]\n"," [ 0 10  3 15  6]]\n","\n"," **** PRODUCED because 15 > 13\n","\n"," Destination: Enviou 0\n","REWARD ******************************\n","REW+PEN+PRO 10.0 0.0 10.0\n","Current state (RENDER):  [[ 5 11  4 18  9]\n"," [ 0 11  4 13  8]\n"," [ 3 11  3 14 13]\n"," [ 0 11  4  7  7]\n"," [ 3 11  4 15 16]\n"," [ 0 11  4  9  9]\n"," [ 3 11  3 15 16]]\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[ 0 12  4 18  7]\n"," [ 0 12  4 13  8]\n"," [ 3 12  3 14 13]\n"," [ 0 12  4  7  7]\n"," [ 3 12  4 15 16]\n"," [ 0 12  4  9  9]\n"," [ 3 12  3 15 16]]\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[ 0 13  4 18  7]\n"," [ 0 13  4 13  8]\n"," [ 3 13  3 14 13]\n"," [ 0 13  4  7  7]\n"," [ 3 13  4 15 16]\n"," [ 0 13  4  9  9]\n"," [ 3 13  3 15 16]]\n","REW+PEN+PRO 0.0 0.0 0.0\n","################################################# Episode:4 Score:10.0\n","Current state (RENDER):  [[0 0 4 4 4]\n"," [0 0 4 8 8]\n"," [0 0 4 7 7]\n"," [0 0 3 3 3]\n"," [0 0 4 4 4]\n"," [0 0 3 6 6]\n"," [0 0 4 6 6]]\n","\n"," **** REJECTED by DO 4  <= DI+LT+act 0 4 1\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 0.0 0.0 10.0\n","Current state (RENDER):  [[2 1 4 4 4]\n"," [0 1 4 8 8]\n"," [0 1 4 7 7]\n"," [0 1 3 3 3]\n"," [0 1 4 4 4]\n"," [0 1 3 6 6]\n"," [0 1 4 6 6]]\n","\n"," **** PRODUCED because 10 > 6\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[ 3  2  4 10  8]\n"," [ 0  2  4  8  8]\n"," [ 0  2  4  7  7]\n"," [ 0  2  3  3  3]\n"," [ 0  2  4  4  4]\n"," [ 0  2  3  6  6]\n"," [ 0  2  4  6  6]]\n","\n"," **** REJECTED by DO 3  <= DI+LT+act 2 3 1\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 0.0 0.0 10.0\n","Current state (RENDER):  [[ 3  3  4 10  8]\n"," [ 0  3  4  8  8]\n"," [ 0  3  4  7  7]\n"," [ 2  3  3  3  3]\n"," [ 0  3  4  4  4]\n"," [ 0  3  3  6  6]\n"," [ 0  3  4  6  6]]\n","\n"," **** REJECTED by DO 6  <= DI+LT+act 3 3 1\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 0.0 0.0 10.0\n","Current state (RENDER):  [[ 3  4  4 10  8]\n"," [ 0  4  4  8  8]\n"," [ 0  4  4  7  7]\n"," [ 0  4  4  7  4]\n"," [ 0  4  4  4  4]\n"," [ 2  4  3  6  6]\n"," [ 0  4  4  6  6]]\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[ 3  5  4 10  8]\n"," [ 0  5  4  8  8]\n"," [ 0  5  4  7  7]\n"," [ 0  5  4  7  4]\n"," [ 0  5  4  4  4]\n"," [ 0  5  4 12  8]\n"," [ 0  5  4  6  6]]\n","\n"," **** REJECTED by DO 8  <= DI+LT+act 5 4 0\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 0.0 0.0 10.0\n","Current state (RENDER):  [[ 3  6  4 10  8]\n"," [ 2  6  4  8  8]\n"," [ 0  6  4  7  7]\n"," [ 0  6  4  7  4]\n"," [ 0  6  4  4  4]\n"," [ 0  6  4 12  8]\n"," [ 0  6  4  6  6]]\n","\n"," **** PRODUCED because 15 > 10\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[ 3  7  4 10  8]\n"," [ 3  7  4 15 13]\n"," [ 0  7  4  7  7]\n"," [ 0  7  4  7  4]\n"," [ 0  7  4  4  4]\n"," [ 0  7  4 12  8]\n"," [ 0  7  4  6  6]]\n","\n"," **** REJECTED by DO 7  <= DI+LT+act 7 4 1\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 0.0 0.0 10.0\n","Current state (RENDER):  [[ 3  8  4 10  8]\n"," [ 3  8  4 15 13]\n"," [ 2  8  4  7  7]\n"," [ 0  8  4  7  4]\n"," [ 0  8  4  4  4]\n"," [ 0  8  4 12  8]\n"," [ 0  8  4  6  6]]\n","\n"," **** REJECTED by DO 12  <= DI+LT+act 8 3 1\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 0.0 0.0 10.0\n","Current state (RENDER):  [[ 3  9  4 10  8]\n"," [ 3  9  4 15 13]\n"," [ 2  9  3 12  4]\n"," [ 0  9  4  7  4]\n"," [ 0  9  4  4  4]\n"," [ 0  9  4 12  8]\n"," [ 0  9  4  6  6]]\n","\n"," **** REJECTED by DO 4  <= DI+LT+act 9 4 0\n","\n"," Destination: Enviou 0\n","REWARD ******************************\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 10.0 0.0 20.0\n","Current state (RENDER):  [[ 5 10  4 10  8]\n"," [ 3 10  4 15 13]\n"," [ 0 10  4 15  6]\n"," [ 0 10  4  7  4]\n"," [ 2 10  4  4  4]\n"," [ 0 10  4 12  8]\n"," [ 0 10  4  6  6]]\n","\n"," **** PRODUCED because 14 > 13\n","REW+PEN+PRO 0.0 0.0 0.0\n","Current state (RENDER):  [[ 3 11  3 14 16]\n"," [ 3 11  4 15 13]\n"," [ 0 11  4 15  6]\n"," [ 0 11  4  7  4]\n"," [ 0 11  4 18  8]\n"," [ 0 11  4 12  8]\n"," [ 0 11  4  6  6]]\n","\n"," **** REJECTED by DO 15  <= DI+LT+act 11 4 0\n","\n"," **** PRODUCED because 18 > 15\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 0.0 0.0 10.0\n","Current state (RENDER):  [[ 3 12  3 14 16]\n"," [ 3 12  4 15 13]\n"," [ 2 12  4 15  6]\n"," [ 0 12  4  7  4]\n"," [ 3 12  4 18 18]\n"," [ 0 12  4 12  8]\n"," [ 0 12  4  6  6]]\n","\n"," **** REJECTED by DO 15  <= DI+LT+act 12 3 0\n","REJECTED vvvvvvvvvvvvvvvvvvvvvvvvvvvv\n","REW+PEN+PRO 0.0 0.0 10.0\n","Current state (RENDER):  [[ 3 13  3 14 16]\n"," [ 3 13  4 15 13]\n"," [ 2 13  3 15  3]\n"," [ 0 13  4  7  4]\n"," [ 3 13  4 18 18]\n"," [ 0 13  4 12  8]\n"," [ 0 13  4  6  6]]\n","REW+PEN+PRO 0.0 0.0 0.0\n","################################################# Episode:5 Score:10.0\n"]}]},{"cell_type":"code","source":["state"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bd3BuDO_djSt","executionInfo":{"status":"ok","timestamp":1682477306882,"user_tz":180,"elapsed":998,"user":{"displayName":"Frederic Menezes Ferreira","userId":"10241081141493327015"}},"outputId":"249d2a85-7866-4cbb-ee5c-a8131e623300"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 0, 4, 4, 4],\n","       [0, 0, 4, 8, 8],\n","       [0, 0, 4, 7, 7],\n","       [0, 0, 3, 3, 3],\n","       [0, 0, 4, 4, 4],\n","       [0, 0, 3, 6, 6],\n","       [0, 0, 4, 6, 6]])"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["env.close()"],"metadata":{"id":"WYsfbFGUDnNB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["env.state"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"79mJPhBR-Fsz","executionInfo":{"status":"ok","timestamp":1682477183179,"user_tz":180,"elapsed":543,"user":{"displayName":"Frederic Menezes Ferreira","userId":"10241081141493327015"}},"outputId":"e78cd316-f560-4393-ca2e-74f1ad6b189e"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 3, 14,  3, 14, 16],\n","       [ 3, 14,  4, 15, 13],\n","       [ 0, 14,  4, 21,  8],\n","       [ 0, 14,  4,  7,  4],\n","       [ 3, 14,  4, 18, 18],\n","       [ 0, 14,  4, 12,  8],\n","       [ 0, 14,  4,  6,  6]])"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["env.DE[0].LT"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eRe9o4uPHJ4i","executionInfo":{"status":"ok","timestamp":1682471866710,"user_tz":180,"elapsed":901,"user":{"displayName":"Frederic Menezes Ferreira","userId":"10241081141493327015"}},"outputId":"5a56ef86-9d46-4fd8-ccbd-a1f6e7ee6672"},"execution_count":72,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":["env.DE[0].FT"],"metadata":{"id":"IgYSOLQRcqyO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **6. Main**"],"metadata":{"id":"LPczwWOws3Ql"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"k4k9dXV1gAvq"},"outputs":[],"source":["# PRINCIPAL\n","\n","\n","env = Somn(Y=10,M=5,N=7,MAXDO=5,MAXAM=5,MAXPR=1.5,MAXPE=10,MAXFT=5,MAXMT=3,MAXTI=2,MAXEU = 10)\n","#lr = 0.001\n","lr = 0.01\n","#n_games = 1000\n","n_games = 10000\n","print('\\n shapes', env.observation_space.shape,env.action_space.n)\n","\n","\n","agent = Agente(gamma=0.99, epsilon = 1.0, alpha=lr, input_dims=env.observation_space.shape,\n","              n_acoes=env.action_space.n, mem_max=50000, # mem_max=1000000,\n","               tamanho_amostra=64, epsilon_end=0.01)\n","              #tamanho_amostra=64, epsilon_end=0.01)\n","try:\n","    agent.load_model()\n","except:\n","    pass\n","scores = []\n","profit = []\n","avg_score = []\n","avg_profi = []\n","losses = []\n","avg_loss = []\n","avg_act = []\n","actiones = []\n","actions = []\n","rewards = []\n","for epi in range(n_games):\n","    done = False\n","    score = 0\n","    xcore = 0\n","    loss = 0\n","\n","    observation = env.reset()\n","    while not done:\n","        action = agent.escolher_acao(observation)        \n","        observation_, reward, done, info, exprofit = env.step(action)\n","        score += reward\n","        xcore += exprofit\n","        actions.append(action)\n","        rewards.append(reward)\n","        agent.salvar_experiencia(observation, action, reward, observation_, done)\n","        observation = observation_\n","        \n","        loss_ = agent.aprender()\n","        if isinstance(loss_, type(None)):\n","            loss += 0\n","        else:\n","            loss += loss_\n","\n","    scores.append(score)\n","    losses.append(loss)\n","    profit.append(xcore)\n","#    actiones.append(actions)\n","    \n","#    if epi >= 100:\n","    avg_score.append(np.mean(scores[-100:]))\n","    avg_profi.append(np.mean(profit[-100:]))\n","    avg_loss.append(np.mean(losses[-100:]))\n","#      avg_act.append(np.mean(actiones[-100:]))\n","    \n","    print(\"jogos: \", epi, \"pontuação: %.2f\" % score, \"action \", action, \"epsilon: %.2f\" % agent.epsilon, \"reward: %.2f\" % reward)\n","agent.save_model()\n","\n","\"\"\"# PLOTTAGEM\"\"\"\n","\n","x = [i+1 for i in range(100, n_games)]\n","f = open(\"log007.txt\",\"w\")\n","f.writelines(str(x))\n","f.writelines(str('\\n avg scores \\n'))\n","f.writelines(str(avg_score))\n","f.writelines(str('\\n avg profit \\n'))\n","f.writelines(str(avg_profi))\n","f.writelines(str('\\n avg loss \\n'))\n","f.writelines(str(avg_loss))\n","#f.writelines(str('\\n avg act \\n'))\n","#f.writelines(str(avg_act))\n","f.writelines(str('\\n Rewards \\n'))\n","f.writelines(str(rewards))\n","f.writelines(str('\\n Action \\n'))\n","f.writelines(str(actions))\n","f.close()\n","\n","import matplotlib.pyplot as plt\n","\n","#x = [i+1 for i in range(100, n_games)]\n","plt.plot(x, avg_score[100:])\n","plt.title(\"Curva de aprendizado\")\n","plt.xlabel(\"Número de Jogos\")\n","plt.ylabel(\"Pontuação\")\n","plt.show()\n","plt.plot(x, avg_loss[100:])\n","plt.title(\"Loss\")\n","plt.xlabel(\"Número de Jogos\")\n","plt.ylabel(\"loss\")\n","plt.show()\n","\n","#plt.plot(x, avg_act)\n","#plt.title(\"Actions\")\n","#plt.xlabel(\"Episode\")\n","#plt.ylabel(\"action avg\")\n","#plt.show()\n","\n","\n","# plt.plot(x, avg_profi)\n","# plt.title(\"Expected profit\")\n","# plt.xlabel(\"Number of episodes\")\n","# plt.ylabel(\"Profit\")\n","# plt.show()\n","\n","\n"]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}